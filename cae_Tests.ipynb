{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import utils.ImagesProcessor as ip\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "import models.CAE as cae\n",
    "\n",
    "ratioTrainTest = 0.8\n",
    "inputShape = np.array([300, 300, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(directory_name):\n",
    "    directory = os.fsencode(directory_name)\n",
    "    imgs = []\n",
    "    filenames = []\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.lower().endswith(\".jpg\"): \n",
    "            img = IP.readImage(directory_name + \"/\" + filename)\n",
    "            img = IP.resizeImage(img, inputShape[:-1])\n",
    "            img = IP.extractChromaticity(img)\n",
    "            imgs.append(img)\n",
    "            filenames.append(filename)\n",
    "    return np.array(imgs), filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:313: RuntimeWarning: divide by zero encountered in log\n",
      "  log_a = np.log(a)\n"
     ]
    }
   ],
   "source": [
    "TRAINING_PATH = \"datasets/jardin_landscape/validation/dataset_train\"\n",
    "NORMAL_PATH = \"datasets/jardin_landscape/validation/dataset_normal\"\n",
    "ANOMALY_PATH = \"datasets/jardin_landscape/validation/dataset_anomaly\"\n",
    "IP = ip.ImagesProcessor()\n",
    "\n",
    "# Load the images\n",
    "X_train, trainFilenames = loadImages(TRAINING_PATH)\n",
    "X_normal, normalFilenames= loadImages(NORMAL_PATH)\n",
    "X_anomaly, anomalyFilenames = loadImages(ANOMALY_PATH)\n",
    "\n",
    "# Normalize them\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_normal = X_normal.astype('float32')/255\n",
    "X_anomaly = X_anomaly.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 300, 300, 3)\n",
      "(12, 300, 300, 3)\n",
      "(18, 300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "#print(X_train)\n",
    "print(X_normal.shape)\n",
    "#print(X_normal)\n",
    "print(X_anomaly.shape)\n",
    "#print(X_anomaly)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore  parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testCAE(nbNeuronsLayer1, nbNeuronsLayer2, nbNeuronsLayer3, batch_size, sizeDataset):\n",
    "    print(\"Testing:\",  nbNeuronsLayer1, \", \", nbNeuronsLayer2, \", \", nbNeuronsLayer3, \", \",batch_size)\n",
    "    time1 = time.time()\n",
    "    np.random.shuffle(X_train)\n",
    "    x_train = X_train[0:sizeDataset]\n",
    "    x_train = x_train[:int(ratioTrainTest*len(x_train))]\n",
    "    x_test = x_train[int(ratioTrainTest*len(x_train)):]\n",
    "    autoencoder = cae.CAE(inputShape,nbNeuronsLayers=[nbNeuronsLayer1, nbNeuronsLayer2, nbNeuronsLayer3], nbConvFilters=(3,3), poolScale=(2, 2))\n",
    "    autoencoder.createModel()\n",
    "    autoencoder.train(x_train, x_test, epochs=100, batch_size=batch_size)\n",
    "    autoencoder.getDeltaError()\n",
    "    \n",
    "    pred_ref = autoencoder.predict(X_train)\n",
    "    #print(\"ref:\", pred_ref)\n",
    "    #print(trainFilenames)\n",
    "    pred_nor = autoencoder.predict(X_normal)\n",
    "    #print(\"normal:\", pred_nor)\n",
    "    #print(normalFilenames)\n",
    "    pred_ano = autoencoder.predict(X_anomaly)\n",
    "    #print(\"anomalies:\", pred_ano)\n",
    "    #print(anomalyFilenames)\n",
    "    autoencoder.freeMemory()\n",
    "    del autoencoder\n",
    "    time2 = time.time()\n",
    "    return accuracy_score(np.append(pred_nor, pred_ano), [1]*len(pred_nor) + [-1]*len(pred_ano)), (time2-time1)*1000\n",
    "#print(testCAE([32, 32, 32], 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRandomsParameters(n):\n",
    "    layer1 = np.random.randint(1, 64, n)\n",
    "    layer2 = np.random.randint(1, 64, n)\n",
    "    layer3 = np.random.randint(1, 64, n)\n",
    "    batch_sizes = np.random.randint(1, 8, n)\n",
    "    return np.array([layer1, layer2, layer3, batch_sizes]).T\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nhyperParameters = generateRandomsParameters(20)\\naccurencies = []\\n\\nfor parameter in hyperParameters:\\n    accurencies.append((parameter, testCAE(parameter[0], parameter[1], parameter[2], parameter[3])))\\nprint(accurencies)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "hyperParameters = generateRandomsParameters(20)\n",
    "accurencies = []\n",
    "\n",
    "for parameter in hyperParameters:\n",
    "    accurencies.append((parameter, testCAE(parameter[0], parameter[1], parameter[2], parameter[3])))\n",
    "print(accurencies)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndatasetSize = np.arange(2,8,1)\\nfig, axe1 = plt.subplots()\\naxes = [testCAE(16, 8, 8, 2, sizeDataset=x) for x in datasetSize]\\naccurencies = [i[0] for i in axes]\\ntimes = [i[1] for i in axes]\\nprint(accurencies)\\ngraph = axe1.plot(datasetSize, accurencies, 'r')\\naxe1.set_xlabel('number of train samples')\\naxe1.set_ylabel('Accuracy', color='r')\\n\\naxe2 = axe1.twinx()\\naxe2.plot(datasetSize, times, 'b')\\naxe2.set_ylabel('Time(s)', color='b')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "datasetSize = np.arange(2,8,1)\n",
    "fig, axe1 = plt.subplots()\n",
    "axes = [testCAE(16, 8, 8, 2, sizeDataset=x) for x in datasetSize]\n",
    "accurencies = [i[0] for i in axes]\n",
    "times = [i[1] for i in axes]\n",
    "print(accurencies)\n",
    "graph = axe1.plot(datasetSize, accurencies, 'r')\n",
    "axe1.set_xlabel('number of train samples')\n",
    "axe1.set_ylabel('Accuracy', color='r')\n",
    "\n",
    "axe2 = axe1.twinx()\n",
    "axe2.plot(datasetSize, times, 'b')\n",
    "axe2.set_ylabel('Time(s)', color='b')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accurencies.sort(key=lambda x: x[1])\n",
    "#print(accurencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 300, 300, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 300, 300, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 150, 150, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 150, 150, 8)       1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 75, 75, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 75, 75, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 38, 38, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 38, 38, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 76, 76, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 76, 76, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 152, 152, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 150, 150, 16)      1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 300, 300, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 300, 300, 3)       435       \n",
      "=================================================================\n",
      "Total params: 4,963\n",
      "Trainable params: 4,963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 300, 300, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 300, 300, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 150, 150, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 150, 150, 8)       1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 75, 75, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 75, 75, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 38, 38, 8)         0         \n",
      "=================================================================\n",
      "Total params: 2,192\n",
      "Trainable params: 2,192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Train on 6 samples, validate on 2 samples\n",
      "Epoch 1/300\n",
      "6/6 [==============================] - 1s 250ms/step - loss: 0.0954 - val_loss: 0.0723\n",
      "Epoch 2/300\n",
      "6/6 [==============================] - 1s 213ms/step - loss: 0.0755 - val_loss: 0.0552\n",
      "Epoch 3/300\n",
      "6/6 [==============================] - 1s 231ms/step - loss: 0.0609 - val_loss: 0.0408\n",
      "Epoch 4/300\n",
      "6/6 [==============================] - 1s 222ms/step - loss: 0.0457 - val_loss: 0.0308\n",
      "Epoch 5/300\n",
      "6/6 [==============================] - 1s 216ms/step - loss: 0.0330 - val_loss: 0.0222\n",
      "Epoch 6/300\n",
      "6/6 [==============================] - 1s 211ms/step - loss: 0.0238 - val_loss: 0.0146\n",
      "Epoch 7/300\n",
      "6/6 [==============================] - 1s 230ms/step - loss: 0.0139 - val_loss: 0.0068\n",
      "Epoch 8/300\n",
      "6/6 [==============================] - 1s 202ms/step - loss: 0.0065 - val_loss: 0.0026\n",
      "Epoch 9/300\n",
      "6/6 [==============================] - 1s 240ms/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 10/300\n",
      "6/6 [==============================] - 2s 260ms/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 11/300\n",
      "6/6 [==============================] - 2s 252ms/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 12/300\n",
      "6/6 [==============================] - 2s 252ms/step - loss: 0.0044 - val_loss: 0.0062\n",
      "Epoch 13/300\n",
      "6/6 [==============================] - 1s 247ms/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 14/300\n",
      "6/6 [==============================] - 2s 268ms/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 15/300\n",
      "6/6 [==============================] - 2s 353ms/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 16/300\n",
      "6/6 [==============================] - 2s 406ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 17/300\n",
      "6/6 [==============================] - 2s 393ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 18/300\n",
      "6/6 [==============================] - 2s 390ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 19/300\n",
      "6/6 [==============================] - 2s 313ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 20/300\n",
      "6/6 [==============================] - 2s 275ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 21/300\n",
      "6/6 [==============================] - 1s 229ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 22/300\n",
      "6/6 [==============================] - 1s 233ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 23/300\n",
      "6/6 [==============================] - 1s 243ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 24/300\n",
      "6/6 [==============================] - 1s 243ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 25/300\n",
      "6/6 [==============================] - 2s 294ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 26/300\n",
      "6/6 [==============================] - 2s 263ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 27/300\n",
      "6/6 [==============================] - 1s 242ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 28/300\n",
      "6/6 [==============================] - 1s 234ms/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 29/300\n",
      "6/6 [==============================] - 1s 234ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 30/300\n",
      "6/6 [==============================] - 1s 236ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 31/300\n",
      "6/6 [==============================] - 1s 224ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 32/300\n",
      "6/6 [==============================] - 2s 263ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 33/300\n",
      "6/6 [==============================] - 2s 283ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 34/300\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 35/300\n",
      "6/6 [==============================] - 1s 215ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 36/300\n",
      "6/6 [==============================] - 1s 209ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 37/300\n",
      "6/6 [==============================] - 1s 201ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 38/300\n",
      "6/6 [==============================] - 1s 192ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 39/300\n",
      "6/6 [==============================] - 1s 185ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 40/300\n",
      "6/6 [==============================] - 1s 195ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 41/300\n",
      "6/6 [==============================] - 1s 197ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 42/300\n",
      "6/6 [==============================] - 1s 190ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 43/300\n",
      "6/6 [==============================] - 1s 226ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 44/300\n",
      "6/6 [==============================] - 1s 231ms/step - loss: 0.0019 - val_loss: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/300\n",
      "6/6 [==============================] - 1s 237ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 46/300\n",
      "6/6 [==============================] - 1s 209ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 47/300\n",
      "6/6 [==============================] - 1s 194ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 48/300\n",
      "6/6 [==============================] - 1s 211ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 49/300\n",
      "6/6 [==============================] - 1s 235ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "errors_ref:  [0.00138168 0.00140164 0.0014339  0.00207056 0.0021465  0.00221234\n",
      " 0.0023838  0.00239298]\n",
      "delta_error:  0.002255207044072449\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train[:int(ratioTrainTest*len(X_train))]\n",
    "x_test = X_train[int(ratioTrainTest*len(X_train)):]\n",
    "autoencoder = cae.CAE(inputShape,nbNeuronsLayers=[16, 8, 8], nbConvFilters=(3,3), poolScale=(2, 2))\n",
    "autoencoder.createModel()\n",
    "autoencoder.train(x_train, x_test, epochs=300, batch_size=2)\n",
    "autoencoder.getDeltaError()\n",
    "\n",
    "pred_ref = autoencoder.predict(X_train)\n",
    "pred_nor = autoencoder.predict(X_normal)\n",
    "pred_ano = autoencoder.predict(X_anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAEmCAYAAADvKGInAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XeYnGW5x/HvL6GkIQmEotKLICDN0EINTREkgChNrkMRlS6oIBwUEFFB4ICiaEQhSJGiIEUCqAcQpAXISQgCUoLSEyAQYspmc58/nndw2Oy8M5vM7Duz8/twzbVT3nJvhtx5+qOIwMzMutev6ADMzJqZk6SZWQ4nSTOzHE6SZmY5nCTNzHI4SZqZ5XCStLqTNFDSLZLekXT9IlznIEl31jO2okjaVtLTRcdhPSePk2xfkg4ETgTWBWYAE4CzI+K+RbzuwcCxwMiImLfIgTY5SQGsHRHPFh2L1Z9Lkm1K0onAhcD3gRWAVYCfAaPrcPlVgWfaIUHWQtJiRcdgiyAi/GizB7A08B7w+ZxjliQl0Veyx4XAktlnOwAvAV8H3gBeBQ7NPjsTmAt0ZPc4HDgDuLLs2qsBASyWvT4EeJ5Umn0BOKjs/fvKzhsJPAK8k/0cWfbZ3cBZwP3Zde4Ehlf43Urxn1QW/17AZ4BngLeAU8uO3xx4AJieHXsxsET22b3Z7zIz+333K7v+ycBrwG9K72XnrJndY9Ps9UeAacAORf+/4ceCD5ck29NWwADgxpxj/hvYEtgY2IiUKE4r+3xFUrL9KCkR/lTSsIg4nVQ6vTYihkTEr/ICkTQY+DGwW0QsRUqEE7o5bhngtuzYZYELgNskLVt22IHAocDywBLAN3JuvSLpz+CjwHeAXwJfBD4JbAt8R9Ia2bGdwAnAcNKf3U7AUQARsV12zEbZ73tt2fWXIZWqv1x+44h4jpRAr5I0CLgMuDwi7s6J1wriJNmelgWmRX51+CDguxHxRkRMJZUQDy77vCP7vCMi/kgqRa2zkPHMBzaQNDAiXo2Iyd0cszvwj4j4TUTMi4hrgKeAz5Ydc1lEPBMRs4DrSAm+kg5S+2sH8FtSArwoImZk958MbAgQEY9GxIPZfacAvwC2r+F3Oj0i5mTxfEBE/BL4B/AQ8GHSP0rWhJwk29ObwPAqbWUfAV4se/1i9t771+iSZP8NDOlpIBExk1RF/SrwqqTbJK1bQzylmD5a9vq1HsTzZkR0Zs9LSez1ss9nlc6X9DFJt0p6TdK7pJLy8JxrA0yNiNlVjvklsAHwk4iYU+VYK4iTZHt6AJhNaoer5BVSVbFkley9hTETGFT2esXyDyPijojYhVSieoqUPKrFU4rp5YWMqScuIcW1dkR8CDgVUJVzcoeNSBpCauf9FXBG1pxgTchJsg1FxDukdrifStpL0iBJi0vaTdK52WHXAKdJWk7S8Oz4KxfylhOA7SStImlp4JTSB5JWkLRn1jY5h1Rt7+zmGn8EPibpQEmLSdoPWA+4dSFj6omlgHeB97JS7pFdPn8dWGOBs/JdBDwaEV8itbX+fJGjtIZwkmxTEXEBaYzkacBU4F/AMcBN2SHfA8YDE4FJwGPZewtzr7uAa7NrPcoHE1s/Ui/5K6Qe3+3JOkW6XONNYI/s2DdJPdN7RMS0hYmph75B6hSaQSrlXtvl8zOAsZKmS/pCtYtJGg18mtTEAOl72FTSQXWL2OrGg8nNzHK4JGlmlsNJ0szaiqTjJT0habKkr1U73knSzNqGpA2AI0iTIzYC9pC0dt45TpJm1k4+DjwYEf/OxvneA+ydd4In3veAFhsYWmKposOwLjb5+CpFh2BdvPjiFKZNm1ZtLGmP9P/QqhHzFpi8tICYNXUyaRxwyZiIGJM9fwI4O5vOOos0X3983vWcJHtASyzFkutUHeFhvez+hy4uOgTrYustRtT9mjFvVk1//2ZP+OnsiOg2gIj4u6RzgLtIY3L/D8hdrcrVbTNrDRL061/9UUVE/CoiNs0WJ3mLNIe+Ipckzax1aNHLdZKWj4g3JK0C7ENa2akiJ0kzax2qSzPn77I2yQ7g6Ih4O+9gJ0kzaxGqS0kyIrbtyfFOkmbWGkRNbY715iRpZi1C9apu94iTpJm1jjpUt3vKSdLMWodLkmZmFZTGSfYyJ0kzax2ubpuZVVKfIUA95SRpZq2jn9skzcy653GSZmZ5XN02M8vnIUBmZjlckjQzq8DjJM3MqnB128ysEnfcmJnlc0nSzKwCCfr1fspykjSz1uGSpJlZDrdJmpnlcEnSzKwCj5M0M8snlyTNzLonnCTNzCqTkNeTNDOrrIiSZO/3p5uZLSRJVR81XOMESZMlPSHpGkkD8o53kjSzlrGoSVLSR4HjgBERsQHQH9g/7xxXt82sJah+bZKLAQMldQCDgFfyDnZJ0sxaRo0lyeGSxpc9vlw6PyJeBs4D/gm8CrwTEXfm3dMlSTNrGTV23EyLiBEVzh8GjAZWB6YD10v6YkRcWeliLkmaWcuoQ8fNzsALETE1IjqA3wMj805wSdLMWoOoR5vkP4EtJQ0CZgE7AePzTnCSNLOWIGob4pMnIh6SdAPwGDAPeBwYk3eOk6SZtYx6DCaPiNOB02s93knSzFpH70+4cZI0sxYh6NfPi+6amVXkVYDMzCqoR8fNwnCSbDNHH7ADh+4zEklc9vv7ufjqu4sOqe3Nnj2bnUdtx9w5c5jXOY+999mXb59+ZtFhNSe3SVojrbfmhzl0n5Fse/CPmNvRyc0/PYrb75vMc/+cWnRobW3JJZdk3F1/YciQIXR0dLDj9tuw66d2Y4sttyw6tOZSUJukZ9y0kXVXX5GHJ01h1uwOOjvn89dHn2X0qI2KDqvtSWLIkCEAdHR0MK+jo5BqZSuox1JpPeUk2UYmP/cK22y6FsssPZiBAxbn09usz0orDis6LAM6OzvZ4pMbs8pHlmfHnXdh8y22KDqk5qQaHnXW0CQpaW9JIWndRt6nSgzvZT8/ko20b1tPv/A6519+F7decgw3//RoJj7zMvPmdRYdlgH9+/fnoUcn8OyUlxj/yMNMfuKJokNqSn2xJHkAcB9VFrXsDRHxSkTsW3QcRRt70wOMPPAcdjn8Qt5+ZybPuj2yqQwdOpTttt+BO+8cV3QoTUcS/fr1q/qot4YlSUlDgK2Bw8mSpKQdJN0t6QZJT0m6Slnql7STpMclTZL0a0lLZu9PkfR9SQ9ka8NtKukOSc9J+mrpXpL+LOmx7PzR3cSzmqQnsuf9Jf1I0iOSJkr6SqP+HJrNcsNS29fKKw5j9I4bcd243Ln91gumTp3K9OnTAZg1axZ/+fOfWGedwipfTa2IkmQje7f3AsZFxDOS3pK0afb+JsD6pNWA7we2ljQeuBzYKTv+CuBI4MLsnH9FxFaS/ic7bmtgADAZ+DkwG9g7It6VNBx4UNLNEREVYjuctNjmZlkyvl/SnRHxQtcDswU706Kdiw9ZlD+PpnDNeV9imaGD6ZjXydd+eB3TZ8wqOqS299qrr3LEYf9FZ2cn82M+n9v3C3xm9z2KDqs59bEhQAfwnyT32+z1bcDDEfESgKQJwGrADNIab89kx48Fji47/+bs5yRgSETMAGZImi1pKDAT+L6k7YD5wEeBFYDXKsS2K7ChpFL1e2lgbWCBJBkRY8hWCek3aPlKSbdl7Hz4hdUPsl71iQ035MHxjxcdRvPrS9MSJS0L7AhsIClIm+0E8EdgTtmhnVkM1f59KJ0zv8v587PzDwKWAz4ZER2SppBKmhVDBI6NiDtq+oXMrHACihgZ1ai0vC9wRUSsGhGrRcTKpFLaNhWOfwpYTdJa2euDgXt6cL+lgTeyBDkKWLXK8XcAR0paHEDSxyQN7sH9zKzXVW+PbKXe7QOAG7u89zvgwO4OjojZwKGk/SYmkUqIP+/B/a4CRmRtmweRkm6eS4Engceyzpxf4NlHZk1Pqv6ot4YkhojYoZv3fgz8uMt7x5Q9/zOpU6freauVPb+c1HGzwGfAVhViGZL9nAJskD2fD5yaPcysFQj61WdL2R5x6cnMWoJwkjQzy1VEx42TpJm1DK8naWZWgdwmaWaWxyuTm5nlcpukmVkOlyTNzCooqk3SK5ObWcuox4wbSetImlD2eFfS1yod75KkmbWMelS3I+JpYOPsev2Bl1lwGvX7KibJbA51d0uDKd0nNly0UM3MeqYBTZI7Ac9FxIuVDsgrSXrVTzNrGj1okxyeLXZTMiZbF7Y7+wPX5F2sYpIsz6ySVgXWjog/SRqYd56ZWWPUPE5yWkSMqHo1aQlgT+CUvOOqdtxIOgK4gbScGMBKwE3V4zQzq686L5W2G/BYRLyed1AtvdtHk/aUeRcgIv4BLN+jUMzM6qDOi+4eQJWqNtRWbZ4TEXNLN5e0GN136JiZNUw9x0lKGgTsAlTdKbWWJHmPpFOBgZJ2AY4Cblm0EM3Meq5eM24i4t/AsrUcW0t1+1vAVNJOhV8hbeZ12kJHZ2a2kJpy+4aImC9pLPAQqZr9dM5+1mZmDdOUc7cl7U7alOs50kDy1SV9JSJub3RwZmYlkpp2PcnzgVER8SyApDWB2wAnSTPrVc26VNobpQSZeR54o0HxmJlV1K+ZqtuS9smeTpb0R+A6Upvk54FHeiE2M7P3NeP2DZ8te/46sH32fCowrGERmZlVUECOzJ27fWhvBmJmVk2z9m4PAA4H1gcGlN6PiMMaGJeZ2QKK6LipZTD5b4AVgU8B95AWuJjRyKDMzLoS0F+q+qi3WpLkWhHxbWBmRIwFdgc+UfdIzMzy1LC4RSOq47UMAerIfk6XtAHwGrBa3SMxM6uiWcdJjpE0DPg2cDMwBPhOQ6MyM+tCNNk4yZKIuDR7eg+wRmPDMTOrrKnGSUo6Me/EiLig/uGYmXWvUav8VJNXklyq16IwM6tBU1W3I+LM3gzEzKyaAgqS3vXQzFqDgP7N1CZpZtZUGjQOshonSTNrGU3VcePebTNrNs1Wkiz1bq8DbEYaSA5pCbV7GxmUmVlXTdcmWerdlnQnsGlEzMhenwFc3yvRmZmVadbe7VWAuWWv5+K522bWy6QmGydZ5jfAw5JuJG3fsDdwRUOjMjPrRlN13JRExNmSbge2zd46NCIeb2xYZmYLqtfcbUlDgUuBDUiFv8Mi4oHujq11CNAg4N2IuEzScpJWj4gX6hKtmVkNhOpZ3b4IGBcR+0pagpTjulXL9g2nAyNIvdyXAYsDVwJb1ydWM7Ma1GmBC0kfArYDDgGIiLl8sN/lA2opSe4NbAI8ll3wFUle/MKaxrDNjik6BOtiztP/bMh1a9yeYbik8WWvx0TEmLLXa5B2fb1M0kbAo8DxETGzu4vVsn3D3IgIUr0dSYNridLMrJ4EtW7fMC0iRpQ9xnS51GLApsAlEbEJMBP4VqX71pIkr5P0C2CopCOAP5EaPM3MelU/VX/U4CXgpYh4KHt9AylpdquW3u3zJO0CvEtql/xORNxVUyhmZnVUj87tiHhN0r8krRMRTwM7AU9WOr6WjptzIuJk4K5u3jMz6xVSXaclHgtclfVsPw8cWunAWqrbu3Tz3m4LGZiZ2UIrbeGQ96hFREzI2is3jIi9IuLtSsfmrQJ0JHAUsKakiWUfLQX8rbZQzMzqoxl3S7wauB34AR/s+ZkREW81NCozs27UUvWtt7xVgN4B3pF0EfBW2SpAS0naoqxnyMys4SQVslRaLYn5EuC9stczs/fMzHpVvdoke6KWGTfKBpMDEBHzJXnbBzPrdQUUJGsqST4v6ThJi2eP40ld5mZmvabUcVPtUW+1JMmvAiOBl0kj1bcAvlz3SMzM8gj696v+qLdaZty8Aexf/1ubmfWMCtjAIW+c5EkRca6kn5AtblEuIo5raGRmZmVSdbv375tXkvx79nN8zjFmZr2mqZJkRNyS/Rzbe+GYmXWv6baUlXQL3VSzSyJiz4ZEZGbWnQaNg6wmr7p9XvZzH2BF0pYNAAcAUxoYk5lZt5pq7nZE3AMg6ayI2K7so1sk3dvwyMzMyjRjx03JcpLWiIjnASStDizX2LDMzLpSrXvc1FUtSfIE4G5JpVk2qwFfaVhEZmbdSHvc9P59axlMPk7S2sC62VtPRcScxoZlZtZF7XvY1FUt2zcMAk4EVo2IIyStne0NcWvjwzMz+48iOm5qmel4GWnj7q2y1y8B32tYRGZm3SiNk6z2qLdakuSaEXEu0AEQEbOyeM3MelWzric5V9JAsoHlktYE3CZpZr1KNNn2DWVOB8YBK0u6CtgaOKSRQZmZLUBNNpgcQJKAp0izbrYkJfPjI2JaL8RmZva+ZtwtkYgISTdFxCeB23opJjOzbhXRGVJLFf9BSZs1PBIzsyqateNmFPBVSVNIOyWKVMjcsP7hmJl1T3WclpjlsxlAJzAvIkZUOraWJLlbXaIyM1tEqm9RcVQt/St560kOIG0CthYwCfhVRMyrX3xmZj3TbG2SY4ERpAS5G3B+r0RkZtYdpZJktQcwXNL4skd3u7sGcKekRyt8/r686vZ6EfEJAEm/Ah5e2N/NzGxRCWptk5yW18aY2ToiXpG0PHCXpKciott1cvNKkh2lJ65mm1kzUA2PWkTEK9nPN4Abgc0rHZtXktxI0rtlsQ3MXpd6tz9UYzxmZnVRj34bSYOBfhExI3u+K/DdSsfnbd/Qf9HDMTOrjzR3uy5dNysAN2btl4sBV0fEuEoH1zIEyMysCagu0xKzrWg2qvV4J0kzaxlNuX2DmVkzqGN1u0ecJM2sNTRobnY1TpJm1jKabqk063uOPmAHDt1nJJK47Pf3c/HVdxcdkuHvpRZpPcnev28Rq6FbQdZb88Mcus9Itj34R2y+3w/YbbsNWHOV5YoOq+35e6mdaviv3pwk28i6q6/Iw5OmMGt2B52d8/nro88yelTNIyGsQfy91K6I9SSdJNvI5OdeYZtN12KZpQczcMDifHqb9VlpxWFFh9X2/L3UpjR3u9qj3pqiTVJSABdExNez198AhkTEGb0Yw+XArRFxQ2/ds7c9/cLrnH/5Xdx6yTHMnDWHic+8zLx5nUWH1fb8vdSqMdXpapoiSZK2qN1H0g8WZpMxSYt5EY7ajL3pAcbe9AAAZx7zWV5+fXrBERn4e6lJQUOAmqW6PQ8YA5zQ9QNJq0r6s6SJ2c9Vsvcvl3SBpP8FzpF0hqSxku6UNEXSPpLOlTRJ0jhJi2fnfUfSI5KekDRGdV7quNktN2wIACuvOIzRO27EdePGFxyRgb+XWrR1dTvzU2CipHO7vH8xcEVEjJV0GPBjYK/ss48BO0dEp6QzgDVJe/KsBzwAfC4iTpJ0I7A7cBNwcUR8F0DSb4A9gFsqBZUtyJkW5Vx8SD1+z0Jdc96XWGboYDrmdfK1H17H9Bmzig7J8PdSqyJKNE2TJCPiXUlXAMcB5f+HbEXa9xvgN0B5Er0+Isobb26PiA5Jk4D+QGllj0nAatnzUZJOAgYBywCTyUmSETGGVMql36DlYyF+taay8+EXFh2CdcPfS43auLpdciFwODA455jyRDWzy2dzACJiPtAREaVj5wOLZfv2/AzYN1t1/ZfAgHoEbmaN1/bjJCPiLeA6UqIs+Ruwf/b8IOC+RbhFKSFOkzQE2HcRrmVmvayfqj/qfs/6X3KRnQ8ML3t9HHCopInAwcDxC3vhiJhOKj1OIrVPPrIIcZpZb6vX/g090BRtkhExpOz566T2wtLrKcCO3ZxzSJfXZ+Rc84yy56cBp1W7npk1l5QD23ecpJlZPi+VZmaWz0nSzKyi9p6WaGZWlUuSZmYVNKjzuionSTNrGUUsteAkaWYtw9VtM7McRVS3m3HGjZnZgmqZbVNjFpXUX9Ljkm6tdqxLkmbWEtJuiXUrSx4P/B34ULUDXZI0s5ZRj4KkpJVI68teWss9XZI0s9ZRW0FyuKTypd3HZOvCllwInAQsVcvFnCTNrGXUOONmWkSM6PZ8aQ/gjYh4VNIOtVzMSdLMWkYd1ovcGthT0mdI68t+SNKVEfHFivdc5FuamfWWRWyUjIhTImKliFiNtJj3X/ISJLgkaWYtwutJmpnlqfN6khFxN3B3teOcJM2sZXhaoplZRV5P0swsl0uSZmYVCCdJM7Ncrm6bmeVwSdLMLIe3bzAzq0TevsHMrCJ33JiZVeHqtplZDpckzcxyuE3SzCyHq9tmZhWozqsA1cpJ0sxahmfcmJnlcEnSzCyHk6SZWUVeT9LMrCLPuDEzq8JJ0swsh6vbZmaVeJykmVllwjNuzMxyee62mVmORc2RkgYA9wJLkvLfDRFxet45TpJm1jLqUI6cA+wYEe9JWhy4T9LtEfFgpROcJM2sZSxqdTsiAngve7l49oi8c/ot0h3NzHpJaTB5tUfV60j9JU0A3gDuioiHco9PidVqIWkq8GLRcdTJcGBa0UHYB/Sl72TViFiunheUNI70Z1TNAGB22esxETGmm+sNBW4Ejo2IJyre10myPUkaHxEjio7D/sPfSe+TdDowMyLOq3SMq9tm1jYkLZeVIJE0ENgZeCrvHHfcmFk7+TAwVlJ/UiHxuoi4Ne8EJ8n2tUAbjRXO30mDRcREYJOenOM2STOzHG6TNDPL4SRpZpbDSdLMLIeTpFWkIpZcsYokfVzSjtmcY+sl7t22bklSNs8VSasAsyJiasFhtbv9gZWBTkl/i4iOogNqB+7dtgV0SZAnAdsAg4DbgLER8VaR8bUrSf2A04AVgeuB+5woG8/VbVtAWYL8DLBTROwJvANsBrxdZGztprzJIyLmA2cDrwL7Adu46t14TpL2PkmbS/pW2VtLAL/L3hsMHBIRIeljxUTYXrqU6HeVtAMwFPge8E9SohzpRNlYrm7b+yQtR1pBZdmImCBpS+BHpPX3RkfEXElfA0YB+0XE7JzLWZ1IOhHYG3gSGAJcGhH/K+lkYEPgkoi4r8gY+zJ33BiSRgHbRMRZkpYklR4fjohjJD1ESpwHZ58dBhzgBNk7JO0MjIqIbSX9ANgcOEASEXGOpBOAZ4uNsm9zSdKQtBYwETgrIn4gaSXg18D4iDhV0mHA+qR9QX4WEU8WGG6fVl7Fzl6vQ9pyYAfgi8DBwP+QFmo4OyLuLCLOduKSZJuT1D8inpX0CeBv2evvSToEuFLSDyLilOzYxd2b2jhd2iC3AJ4BXsiaOdYmVatflfQ4aVXt/ysw3LbhJNmmSn8hI6IzS4zPSdqWtDESWaL8IvAHSUtGxInAvILD7tPKEuRXgW8Ck4E7Jf0WeIK0xNemwB7A3hHxemHBthEnyTbUpcTyOWCwpGcj4m+SRgL3S5ofEd+XtCdpsyTCbTMN0eX7WJ7UGbM5MALYBTgcuJg0DGsLYP+IeL6gcNuOk2QbKvsLeQypnWsM8CdJh0TEdVmifFrS3Lxl7W3RdUmQRwMfAdaPiDeBO7IB5DsDJwEXRcQfi4u2PXmcZJvKqm37ArsCA4F/AOdIOiwingPWBm4uMMS2UJYgRwMHAA8BH5V0bfb57cC9pNK859IXwL3bbaJrr2n23oeBLYHjImKUpKNI1bq9IsIJsoG6lCBHAKcAt0fEpdksm8eApyLigOyYwRExs7iI25dLkm2i7C/kSEmfyt57FRhGGqQM8BpwHWk4kDVIlwS5D7AbabrnKEkbZZ9tCmwp6XIAJ8jiuCTZx3X5C3kscBTwJjAT2J3UEXAkaQzk6sC+ETGlmGjbi6Qdga8DewEfJ7UPzwBuiohJ2TGrR8QLxUVpLkn2YV0S5ADS971FRGxD2rz9KlKp8VzgDuAgJ8jekc3DPhKYGBEd2QZVfyDNkT9Q0voATpDFc5Lso7okyOOAu4BDgM8ARMRoUunxBuDJiLg0Ip4uKNw+r5sFjF8A3gLWlrQhQETcD4wDOgCPgWwSrm73cdkiFUcDVwDbAcOBP0TEuOzzq4GTI+JfxUXZt3X5B+uzpEH504HxwEWkZHltWRV7YETMKipe+yCXJPswSduTqnATIuIu4HLg78DobMgJEXGgE2TvyEYPfJe0iPGvgROyx1DgEEnrAThBNhcnyT6ka5UuIu4Brga+KGnpbPzjzcAUUk/q4G6qgVYnklbJhu5ENpPm88CBEfHfwEjgK6SxqmcD/Unzsa3JuLrdR3Sp0u0JrAA8HRH3SvoRsBXw2Yh4W2nPmhkR4VXGG0TSCsCpwL+An0fEe5KuB76V/WNV+p62joiTvXhI83JJso8oS5Ankv5ybgwcLunnEfFN0kyOeyQNjYh/OkE23FTgEdI0w0OzEvvzwG8llaYDrwqsJKk/XjykaXnudh+SDfPZirSK+OuSVgZOkHRURHxd0sXA0qROA2uAbEmzfhHxtKSrSItS7AYckZUYLwHulTSRNEb1oIjoLDBkq8LV7RbWzQKtSwH3AOdHxFXZ4ggHAyMi4tii4mwXkpYllSCnAWcCnaTFQw4E1gJejYhfZGtFDgRe9DjI5ueSZIvq0ga5JfBaREyR9N/AcZKmR8RtWTVveUkDgdle7qxxIuJNpe0W/kRqytoIuJa0R9Bc4BPZ93FZRMwpLlLrCZckW1CXBHkkcBzwLmkGzT3AGsBPSAOTtyMtWOEtF3qJpF2AH5OS5ArAjsD+pDUiXyV11rxTXITWE06SLSwb67g/ac7vVqSltp4jDRwfQFq84u2IeKmwINuUpN1Je9FsGRFvSRpGWu5skKd+thZXt1uIpBVKS/ZLWpq07/ImWcP/fVkv6X7AMaQq3aTiom1vWVPHfOBBSVtli+haC/IQoBYhaV3gVUkXSDo8q659D5iY9VqXBo//jtSDPaO4aA3eXzD3m6RV3/13rUW5ut0isuE8vyXNmNkJeIk05fBt0hCTgRHxtexYz/1tIpKGRMR7RcdhC8f/urWIbH71w6TFWD9D6kE9GPghqR1yO0mnZIfPLiRI65YTZGtzkmwBZfOrTwaCtJLPK8AnScv8jyYtovs78K6GZvXkjpsWkC2QINJGUM8CF5BKlCdExE2SVgfeiYi3iozTrC9ym2SLkbQO8FfgJxFxVtHxmPV1rm63mGz18JOB/pIGFR2PWV/nJNmaHiC1R5pZg7m63aIkDYqIfxcdh1lf5yRpZpbD1W0zsxxOkmbfeujEAAAB8klEQVRmOZwkzcxyOEmameVwkrSGkrSspAnZ4zVJL5e9XqKO99lZ0k1VjvmSpAt7eN2XJA1dtOislXlaojVUto7ixgCSzgDei4jzyo8pTbmMiPm9H6FZPpckrRCS1pL0hKSfkxbpWFnS9LLP95d0afZ8BUm/lzRe0sPZnj55195S0gOSHpd0f7aDYcmqku6Q9LSk08rO+a/s2hMk/czrP1qJ/0ewIq0H/CoiNgFezjnux8C5ETEC+AJwaZXr/h3YJrvuWaTFiUs2J215sSlwoKSNJW0A7A2MjIiNSTWs/RfmF7K+x9VtK9JzEfFIDcftDKzznxXjGFZlYeGhwBWS1uzmszsi4m2ArA1zG9Lfg82A8dk9BgL/qv3XsL7MSdKKNLPs+XzSUnAlA8qeC9g8IubWeN2zScnwZ5LWIu0aWdJ1illk1/91RHy7xutbG3F125pC1mnztqS1s/bAvcs+/hNwdOmFpI2rXG5p/lN9P6TLZ7tKGpqtoDQauD+7/hckDc+uv6ykVRb6l7E+xUnSmsnJpFLfn0l7+JQcDWwtaaKkJ4EjqlznHOBHku7v5rP7gKuBx4FrImJCtqvkmaQNuyYCd5L2yzbzAhdmZnlckjQzy+EkaWaWw0nSzCyHk6SZWQ4nSTOzHE6SZmY5nCTNzHL8Py/Uuqj1yCFVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c2e7745f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(np.append(pred_nor, pred_ano), [1]*len(pred_nor) + [-1]*len(pred_ano))\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):     \n",
    "    labels_names_ref = [\"Anomalie\", \"Normal\"]\n",
    "        \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels_names_ref))\n",
    "    plt.xticks(tick_marks, labels_names_ref, rotation=45)\n",
    "    plt.yticks(tick_marks, labels_names_ref)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Predicted label')\n",
    "    plt.xlabel('True label')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "plot_confusion_matrix(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "Precision:  0.625\n",
      "Recall:  0.625\n",
      "F1-Score:  0.625\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(np.append(pred_nor, pred_ano), [1]*len(pred_nor) + [-1]*len(pred_ano)))\n",
    "precision = (conf_mat[0][0]/(conf_mat[0][0] + conf_mat[1][0]) + conf_mat[1][1]/(conf_mat[1][1] + conf_mat[0][1]))/2\n",
    "print(\"Precision: \", precision)\n",
    "recall = (conf_mat[0][0]/(conf_mat[0][0] + conf_mat[0][1]) + conf_mat[1][1]/(conf_mat[1][1] + conf_mat[1][0]))/2\n",
    "print(\"Recall: \", recall)\n",
    "f1score = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F1-Score: \", f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA_IMG_0360.jpg  -  1\n",
      "NA_IMG_0362.jpg  -  1\n",
      "NA_IMG_0376.jpg  -  1\n",
      "NA_0244.jpg  -  -1\n",
      "NA_IMG_0411.jpg  -  -1\n",
      "NA_0240.jpg  -  -1\n",
      "NA_IMG_0366.jpg  -  1\n",
      "NA_IMG_0428.jpg  -  1\n",
      "NA_IMG_0370.jpg  -  1\n",
      "NA_IMG_0364.jpg  -  1\n",
      "NA_IMG_0385.jpg  -  1\n",
      "NA_IMG_0278.jpg  -  1\n",
      "A_IMG_0321.jpg  -  -1\n",
      "A_IMG_0322.jpg  -  1\n",
      "HA_IMG_0425.jpg  -  -1\n",
      "HA_IMG_0424.jpg  -  -1\n",
      "HA_IMG_0418.jpg  -  -1\n",
      "A_IMG_0423.jpg  -  -1\n",
      "A_IMG_0345.jpg  -  1\n",
      "A_IMG_0390.jpg  -  1\n",
      "A_IMG_0409.jpg  -  -1\n",
      "A_IMG_0353.jpg  -  1\n",
      "A_IMG_0395.jpg  -  1\n",
      "HA_IMG_0420.jpg  -  -1\n",
      "A_IMG_0417.jpg  -  -1\n",
      "A_IMG_0402.jpg  -  1\n",
      "A_IMG_0413.jpg  -  -1\n",
      "A_IMG_0272.jpg  -  1\n",
      "A_IMG_0271.jpg  -  1\n",
      "A_IMG_0329.jpg  -  1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(normalFilenames)):\n",
    "    print(normalFilenames[i], \" - \", pred_nor[i])\n",
    "for i in range(len(anomalyFilenames)):\n",
    "    print(anomalyFilenames[i], \" - \", pred_ano[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
