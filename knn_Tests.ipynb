{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import utils.ImagesProcessor as ip\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import itertools\n",
    "import time\n",
    "import models.CAE as cae\n",
    "\n",
    "slicesSize = np.array([28, 28, 3])\n",
    "overlap = 5\n",
    "ratioTrainTest = 0.8\n",
    "inputShape = np.array([300, 300, 3])\n",
    "K = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(directory_name):\n",
    "    directory = os.fsencode(directory_name)\n",
    "    imgs = []\n",
    "    filenames = []\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.lower().endswith(\".jpg\"): \n",
    "            img = IP.readImage(directory_name + \"/\" + filename)\n",
    "            img = IP.resizeImage(img, inputShape[:-1])\n",
    "            img = IP.extractChromaticity(img)\n",
    "            img_slices = IP.sliceImage(img,(slicesSize[0], slicesSize[1]),overlap)\n",
    "            imgs.append(img_slices)\n",
    "            filenames.append(filename)\n",
    "    return np.array(imgs), filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:313: RuntimeWarning: divide by zero encountered in log\n",
      "  log_a = np.log(a)\n"
     ]
    }
   ],
   "source": [
    "TRAINING_PATH = \"datasets/jardin_landscape/validation/dataset_train\"\n",
    "NORMAL_PATH = \"datasets/jardin_landscape/validation/dataset_normal\"\n",
    "ANOMALY_PATH = \"datasets/jardin_landscape/validation/dataset_anomaly\"\n",
    "IP = ip.ImagesProcessor()\n",
    "\n",
    "# Load the images\n",
    "X_train, trainFilenames = loadImages(TRAINING_PATH)\n",
    "X_normal, normalFilenames= loadImages(NORMAL_PATH)\n",
    "X_anomaly, anomalyFilenames = loadImages(ANOMALY_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 196, 28, 28, 3)\n",
      "(12, 196, 28, 28, 3)\n",
      "(18, 196, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "# Normalize them\n",
    "X_train = X_train.astype('float32')/255.0\n",
    "X_normal = X_normal.astype('float32')/255.0\n",
    "X_anomaly = X_anomaly.astype('float32')/255.0\n",
    "\n",
    "print(X_train.shape)\n",
    "#print(X_train)\n",
    "print(X_normal.shape)\n",
    "#print(X_normal)\n",
    "print(X_anomaly.shape)\n",
    "#print(X_anomaly)\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the KNN needed functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidienne_distance(data1, data2):    \n",
    "    return np.sum(np.power(np.array(data1) - np.array(data2), 2))\n",
    "\n",
    "def manhattan_distance(data1, data2): \n",
    "    return np.sum(np.absolute(np.array(data1) - np.array(data2)))\n",
    "\n",
    "\n",
    "def get_neighbors(training_set, \n",
    "          data_point, \n",
    "          k, \n",
    "          distance=euclidienne_distance):\n",
    "    distances = []\n",
    "    for indexTrain in range(len(training_set)):\n",
    "        dist = distance(data_point, training_set[indexTrain])\n",
    "        distances.append(dist)\n",
    "    distances.sort()\n",
    "    neighbors = distances[:k]\n",
    "    mean_distance = np.max(neighbors)\n",
    "    return mean_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore  parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testKNN(datasetSize):\n",
    "    time1 = time.time()\n",
    "    x_temp = X_train.reshape(-1, slicesSize[0], slicesSize[1], slicesSize[2])\n",
    "    x_temp = x_temp[0:datasetSize]\n",
    "    x_temp = np.random.permutation(x_temp)\n",
    "    x_train = x_temp[:int(ratioTrainTest*len(x_temp))]\n",
    "    x_test = x_temp[int(ratioTrainTest*len(x_temp)):]\n",
    "    autoencoder = cae.CAE(slicesSize,nbNeuronsLayers=[16, 8, 8], nbConvFilters=(3,3), poolScale=(2, 2))\n",
    "    autoencoder.createModel()\n",
    "    autoencoder.train(x_train, x_test, epochs=300, batch_size=64)\n",
    "    \n",
    "    X_train_features = []\n",
    "    for img in X_train:\n",
    "        X_train_features.append(autoencoder.extractFeatures(img))\n",
    "    X_train_features = np.array(X_train_features)\n",
    "    print(X_train_features.shape)\n",
    "\n",
    "    X_normal_features = []\n",
    "    for img in X_normal:\n",
    "        X_normal_features.append(autoencoder.extractFeatures(img))\n",
    "    X_normal_features = np.array(X_normal_features)\n",
    "    print(X_normal_features.shape)\n",
    "\n",
    "    X_anomaly_features = []\n",
    "    for img in X_anomaly:\n",
    "        X_anomaly_features.append(autoencoder.extractFeatures(img))\n",
    "    X_anomaly_features = np.array(X_anomaly_features)\n",
    "    print(X_anomaly_features.shape)\n",
    "\n",
    "    train_distances = []\n",
    "    for img_index in range(X_train_features.shape[0]):\n",
    "        slices_distances = []\n",
    "        for slice_img in X_train_features[img_index]:\n",
    "            slices_distances.append(get_neighbors(X_train_features.reshape(-1, X_train_features.shape[2], X_train_features.shape[3], X_train_features.shape[4]), slice_img, K+1))\n",
    "        train_distances.append(np.max(slices_distances))\n",
    "        print(trainFilenames[img_index], \" - mean : \", np.max(slices_distances))\n",
    "\n",
    "    deltaError = np.max(train_distances)#np.percentile(train_distances, 75)\n",
    "    print(\"deltaError=\", deltaError)\n",
    "\n",
    "    test_distances = []\n",
    "    for img_index in range(X_normal_features.shape[0]):\n",
    "        classe = 1\n",
    "        for slice_img in X_normal_features[img_index]:\n",
    "            slices_distance = get_neighbors(X_train_features.reshape(-1, X_train_features.shape[2], X_train_features.shape[3], X_train_features.shape[4]), slice_img, K)\n",
    "        #mean = np.mean(slices_distances)\n",
    "            if slices_distance > deltaError:\n",
    "                classe = -1\n",
    "                break\n",
    "\n",
    "\n",
    "        print(normalFilenames[img_index], \" - classe : \", classe)\n",
    "        test_distances.append(classe)\n",
    "\n",
    "    for img_index in range(X_anomaly_features.shape[0]):\n",
    "        slices_distances = []\n",
    "        for slice_img in X_anomaly_features[img_index]:\n",
    "            slices_distance = get_neighbors(X_train_features.reshape(-1, X_train_features.shape[2], X_train_features.shape[3], X_train_features.shape[4]), slice_img, K)\n",
    "        #mean = np.mean(slices_distances)\n",
    "            #print(slices_distance)\n",
    "            if slices_distance > deltaError:\n",
    "                classe = -1\n",
    "                break\n",
    "        test_distances.append(classe)\n",
    "        print(anomalyFilenames[img_index], \" - classe : \", classe)\n",
    "    time2 = time.time()\n",
    "    return accuracy_score(test_distances, [1]*len(X_normal_features) + [-1]*len(X_anomaly_features)), (time2-time1)*1000\n",
    "#print(testCAE())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndatasetSize = np.arange(2,8,1)\\nfig, axe1 = plt.subplots()\\naxes = [testKNN(x) for x in datasetSize]\\naccurencies = [i[0] for i in axes]\\ntimes = [i[1] for i in axes]\\nprint(accurencies)\\ngraph = axe1.plot(datasetSize, accurencies, 'r')\\naxe1.set_xlabel('number of train samples')\\naxe1.set_ylabel('Accuracy', color='r')\\n\\naxe2 = axe1.twinx()\\naxe2.plot(datasetSize, times, 'b')\\naxe2.set_ylabel('Time(s)', color='b')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "datasetSize = np.arange(2,8,1)\n",
    "fig, axe1 = plt.subplots()\n",
    "axes = [testKNN(x) for x in datasetSize]\n",
    "accurencies = [i[0] for i in axes]\n",
    "times = [i[1] for i in axes]\n",
    "print(accurencies)\n",
    "graph = axe1.plot(datasetSize, accurencies, 'r')\n",
    "axe1.set_xlabel('number of train samples')\n",
    "axe1.set_ylabel('Accuracy', color='r')\n",
    "\n",
    "axe2 = axe1.twinx()\n",
    "axe2.plot(datasetSize, times, 'b')\n",
    "axe2.set_ylabel('Time(s)', color='b')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 3)         435       \n",
      "=================================================================\n",
      "Total params: 4,963\n",
      "Trainable params: 4,963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 8)           0         \n",
      "=================================================================\n",
      "Total params: 2,192\n",
      "Trainable params: 2,192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Train on 1097 samples, validate on 275 samples\n",
      "Epoch 1/100\n",
      "1097/1097 [==============================] - 2s 1ms/step - loss: 0.0733 - val_loss: 0.0207\n",
      "Epoch 2/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0106 - val_loss: 0.0063\n",
      "Epoch 3/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 4/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 5/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 6/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 7/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 8/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 9/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 10/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 11/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 12/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 13/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 14/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 15/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 16/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 17/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 18/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 19/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 20/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 21/100\n",
      "1097/1097 [==============================] - 1s 996us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 22/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 9.7525e-04 - val_loss: 0.0010\n",
      "Epoch 23/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 9.5483e-04 - val_loss: 0.0010\n",
      "Epoch 24/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 9.3963e-04 - val_loss: 0.0010\n",
      "Epoch 25/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 9.2549e-04 - val_loss: 0.0010\n",
      "Epoch 26/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 9.0849e-04 - val_loss: 9.7818e-04\n",
      "Epoch 27/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 9.0082e-04 - val_loss: 9.6576e-04\n",
      "Epoch 28/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.9577e-04 - val_loss: 9.5730e-04\n",
      "Epoch 29/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.8200e-04 - val_loss: 9.5268e-04\n",
      "Epoch 30/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.7168e-04 - val_loss: 9.4266e-04\n",
      "Epoch 31/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.6444e-04 - val_loss: 9.3711e-04\n",
      "Epoch 32/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.5909e-04 - val_loss: 9.4765e-04\n",
      "Epoch 33/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.6319e-04 - val_loss: 9.4777e-04\n",
      "Epoch 34/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.5892e-04 - val_loss: 9.4361e-04\n",
      "Epoch 35/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.4387e-04 - val_loss: 9.2002e-04\n",
      "Epoch 36/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.4137e-04 - val_loss: 9.1315e-04\n",
      "Epoch 37/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.3502e-04 - val_loss: 9.0579e-04\n",
      "Epoch 38/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.3095e-04 - val_loss: 9.0725e-04\n",
      "Epoch 39/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.2825e-04 - val_loss: 8.9599e-04\n",
      "Epoch 40/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.2176e-04 - val_loss: 8.9334e-04\n",
      "Epoch 41/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.1902e-04 - val_loss: 8.8371e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.1891e-04 - val_loss: 8.8076e-04\n",
      "Epoch 43/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.1661e-04 - val_loss: 8.7702e-04\n",
      "Epoch 44/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.1047e-04 - val_loss: 8.7456e-04\n",
      "Epoch 45/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.0645e-04 - val_loss: 8.7675e-04\n",
      "Epoch 46/100\n",
      "1097/1097 [==============================] - 1s 993us/step - loss: 8.0615e-04 - val_loss: 8.6793e-04\n",
      "Epoch 47/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.1005e-04 - val_loss: 8.7914e-04\n",
      "Epoch 48/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 8.0157e-04 - val_loss: 8.6061e-04\n",
      "Epoch 49/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.9336e-04 - val_loss: 8.6040e-04\n",
      "Epoch 50/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.9083e-04 - val_loss: 8.5616e-04\n",
      "Epoch 51/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.8710e-04 - val_loss: 8.5061e-04\n",
      "Epoch 52/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.8686e-04 - val_loss: 8.7121e-04\n",
      "Epoch 53/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.8348e-04 - val_loss: 8.4497e-04\n",
      "Epoch 54/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.8373e-04 - val_loss: 8.4287e-04\n",
      "Epoch 55/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.8605e-04 - val_loss: 8.3959e-04\n",
      "Epoch 56/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.8638e-04 - val_loss: 8.3890e-04\n",
      "Epoch 57/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.6848e-04 - val_loss: 8.6850e-04\n",
      "Epoch 58/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.8259e-04 - val_loss: 8.3082e-04\n",
      "Epoch 59/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.6834e-04 - val_loss: 8.3100e-04\n",
      "Epoch 60/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.6275e-04 - val_loss: 8.2156e-04\n",
      "Epoch 61/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.6032e-04 - val_loss: 8.2252e-04\n",
      "Epoch 62/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.5625e-04 - val_loss: 8.2904e-04\n",
      "Epoch 63/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.5793e-04 - val_loss: 8.3687e-04\n",
      "Epoch 64/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.7514e-04 - val_loss: 8.1085e-04\n",
      "Epoch 65/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.4139e-04 - val_loss: 7.9917e-04\n",
      "Epoch 66/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.3008e-04 - val_loss: 7.8130e-04\n",
      "Epoch 67/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 7.1454e-04 - val_loss: 7.6099e-04\n",
      "Epoch 68/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 6.8560e-04 - val_loss: 7.1854e-04\n",
      "Epoch 69/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 6.3704e-04 - val_loss: 6.5394e-04\n",
      "Epoch 70/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 5.6335e-04 - val_loss: 5.6189e-04\n",
      "Epoch 71/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 5.0342e-04 - val_loss: 5.4650e-04\n",
      "Epoch 72/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 4.8151e-04 - val_loss: 4.9643e-04\n",
      "Epoch 73/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 4.5120e-04 - val_loss: 4.8122e-04\n",
      "Epoch 74/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 4.4038e-04 - val_loss: 4.6279e-04\n",
      "Epoch 75/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 4.2916e-04 - val_loss: 4.5406e-04\n",
      "Epoch 76/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 4.1113e-04 - val_loss: 4.6257e-04\n",
      "Epoch 77/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 4.0398e-04 - val_loss: 4.3786e-04\n",
      "Epoch 78/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 4.0067e-04 - val_loss: 4.5155e-04\n",
      "Epoch 79/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.9811e-04 - val_loss: 4.4834e-04\n",
      "Epoch 80/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.9128e-04 - val_loss: 4.4289e-04\n",
      "Epoch 81/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.8013e-04 - val_loss: 4.3170e-04\n",
      "Epoch 82/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.7010e-04 - val_loss: 4.0443e-04\n",
      "Epoch 83/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.6460e-04 - val_loss: 4.0759e-04\n",
      "Epoch 84/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.6386e-04 - val_loss: 4.0282e-04\n",
      "Epoch 85/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.6339e-04 - val_loss: 3.8686e-04\n",
      "Epoch 86/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.5321e-04 - val_loss: 3.8888e-04\n",
      "Epoch 87/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.4633e-04 - val_loss: 3.9332e-04\n",
      "Epoch 88/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.4813e-04 - val_loss: 4.0038e-04\n",
      "Epoch 89/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.3928e-04 - val_loss: 3.6990e-04\n",
      "Epoch 90/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.3200e-04 - val_loss: 3.6345e-04\n",
      "Epoch 91/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.2798e-04 - val_loss: 3.6358e-04\n",
      "Epoch 92/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.2705e-04 - val_loss: 3.6515e-04\n",
      "Epoch 93/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.2574e-04 - val_loss: 3.8262e-04\n",
      "Epoch 94/100\n",
      "1097/1097 [==============================] - 1s 984us/step - loss: 3.2537e-04 - val_loss: 3.5834e-04\n",
      "Epoch 95/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.1841e-04 - val_loss: 3.4425e-04\n",
      "Epoch 96/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.1158e-04 - val_loss: 3.4402e-04\n",
      "Epoch 97/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.1026e-04 - val_loss: 3.5909e-04\n",
      "Epoch 98/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.1324e-04 - val_loss: 3.3991e-04\n",
      "Epoch 99/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.0582e-04 - val_loss: 3.3380e-04\n",
      "Epoch 100/100\n",
      "1097/1097 [==============================] - 1s 1ms/step - loss: 3.0089e-04 - val_loss: 3.3865e-04\n"
     ]
    }
   ],
   "source": [
    "x_temp = X_train.reshape(-1, slicesSize[0], slicesSize[1], slicesSize[2])\n",
    "x_temp = np.random.permutation(x_temp)\n",
    "x_train = x_temp[:int(ratioTrainTest*len(x_temp))]\n",
    "x_test = x_temp[int(ratioTrainTest*len(x_temp)):]\n",
    "autoencoder = cae.CAE(slicesSize,nbNeuronsLayers=[16, 8, 8], nbConvFilters=(3,3), poolScale=(2, 2))\n",
    "autoencoder.createModel()\n",
    "autoencoder.train(x_train, x_test, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 196, 4, 4, 8)\n",
      "(12, 196, 4, 4, 8)\n",
      "(18, 196, 4, 4, 8)\n",
      "NA_IMG_0260.jpg  - mean :  0.045600574\n",
      "NA_IMG_0273.jpg  - mean :  0.03573832\n",
      "NA_IMG_0388.jpg  - mean :  0.019053597\n",
      "NA_IMG_0377.jpg  - mean :  0.018485408\n",
      "NA_0268.jpg  - mean :  0.04617075\n",
      "NA_IMG_0426.jpg  - mean :  0.026509022\n",
      "NA_0267.jpg  - mean :  0.021681115\n",
      "deltaError= 0.04617075\n",
      "NA_IMG_0360.jpg  - classe :  1\n",
      "NA_IMG_0362.jpg  - classe :  1\n",
      "NA_IMG_0376.jpg  - classe :  1\n",
      "NA_0244.jpg  - classe :  1\n",
      "NA_IMG_0411.jpg  - classe :  -1\n",
      "NA_0240.jpg  - classe :  1\n",
      "NA_IMG_0366.jpg  - classe :  1\n",
      "NA_IMG_0428.jpg  - classe :  1\n",
      "NA_IMG_0370.jpg  - classe :  1\n",
      "NA_IMG_0364.jpg  - classe :  1\n",
      "NA_IMG_0385.jpg  - classe :  1\n",
      "NA_IMG_0278.jpg  - classe :  1\n",
      "A_IMG_0321.jpg  - classe :  1\n",
      "A_IMG_0322.jpg  - classe :  1\n",
      "HA_IMG_0425.jpg  - classe :  -1\n",
      "HA_IMG_0424.jpg  - classe :  -1\n",
      "HA_IMG_0418.jpg  - classe :  -1\n",
      "A_IMG_0423.jpg  - classe :  -1\n",
      "A_IMG_0345.jpg  - classe :  -1\n",
      "A_IMG_0390.jpg  - classe :  -1\n",
      "A_IMG_0409.jpg  - classe :  -1\n",
      "A_IMG_0353.jpg  - classe :  -1\n",
      "A_IMG_0395.jpg  - classe :  -1\n",
      "HA_IMG_0420.jpg  - classe :  -1\n",
      "A_IMG_0417.jpg  - classe :  -1\n",
      "A_IMG_0402.jpg  - classe :  -1\n",
      "A_IMG_0413.jpg  - classe :  -1\n",
      "A_IMG_0272.jpg  - classe :  -1\n",
      "A_IMG_0271.jpg  - classe :  -1\n",
      "A_IMG_0329.jpg  - classe :  -1\n"
     ]
    }
   ],
   "source": [
    "X_train_features = []\n",
    "for img in X_train:\n",
    "    X_train_features.append(autoencoder.extractFeatures(img))\n",
    "X_train_features = np.array(X_train_features)\n",
    "print(X_train_features.shape)\n",
    "\n",
    "X_normal_features = []\n",
    "for img in X_normal:\n",
    "    X_normal_features.append(autoencoder.extractFeatures(img))\n",
    "X_normal_features = np.array(X_normal_features)\n",
    "print(X_normal_features.shape)\n",
    "\n",
    "X_anomaly_features = []\n",
    "for img in X_anomaly:\n",
    "    X_anomaly_features.append(autoencoder.extractFeatures(img))\n",
    "X_anomaly_features = np.array(X_anomaly_features)\n",
    "print(X_anomaly_features.shape)\n",
    "\n",
    "train_distances = []\n",
    "for img_index in range(X_train_features.shape[0]):\n",
    "    slices_distances = []\n",
    "    for slice_img in X_train_features[img_index]:\n",
    "        slices_distances.append(get_neighbors(X_train_features.reshape(-1, X_train_features.shape[2], X_train_features.shape[3], X_train_features.shape[4]), slice_img, K+1))\n",
    "    train_distances.append(np.max(slices_distances))\n",
    "    print(trainFilenames[img_index], \" - mean : \", np.max(slices_distances))\n",
    "\n",
    "deltaError = np.max(train_distances)#np.percentile(train_distances, 75)\n",
    "print(\"deltaError=\", deltaError)\n",
    "\n",
    "test_distances = []\n",
    "for img_index in range(X_normal_features.shape[0]):\n",
    "    classe = 1\n",
    "    for slice_img in X_normal_features[img_index]:\n",
    "        slices_distance = get_neighbors(X_train_features.reshape(-1, X_train_features.shape[2], X_train_features.shape[3], X_train_features.shape[4]), slice_img, K)\n",
    "\n",
    "        if slices_distance > deltaError:\n",
    "            classe = -1\n",
    "            break\n",
    "           \n",
    "            \n",
    "    print(normalFilenames[img_index], \" - classe : \", classe)\n",
    "    test_distances.append(classe)\n",
    "    \n",
    "for img_index in range(X_anomaly_features.shape[0]):\n",
    "    slices_distances = []\n",
    "    for slice_img in X_anomaly_features[img_index]:\n",
    "        slices_distance = get_neighbors(X_train_features.reshape(-1, X_train_features.shape[2], X_train_features.shape[3], X_train_features.shape[4]), slice_img, K)\n",
    "        \n",
    "        if slices_distance > deltaError:\n",
    "            classe = -1\n",
    "            break\n",
    "    test_distances.append(classe)\n",
    "    print(anomalyFilenames[img_index], \" - classe : \", classe)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c3b0d4da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(test_distances)\n",
    "print([1]*len(X_normal_features) + [-1]*len(X_anomaly_features))\n",
    "conf_mat = confusion_matrix(test_distances, [1]*len(X_normal_features) + [-1]*len(X_anomaly_features))\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):     \n",
    "    labels_names_ref = [\"Anomalie\", \"Normal\"]\n",
    "        \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels_names_ref))\n",
    "    plt.xticks(tick_marks, labels_names_ref, rotation=45)\n",
    "    plt.yticks(tick_marks, labels_names_ref)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Predicted label')\n",
    "    plt.xlabel('True label')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "plot_confusion_matrix(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Precision:  0.9027777777777777\n",
      "Recall:  0.8936651583710407\n",
      "F1-Score:  0.8981983557810039\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(test_distances, [1]*len(X_normal_features) + [-1]*len(X_anomaly_features)))\n",
    "precision = (conf_mat[0][0]/(conf_mat[0][0] + conf_mat[1][0]) + conf_mat[1][1]/(conf_mat[1][1] + conf_mat[0][1]))/2\n",
    "print(\"Precision: \", precision)\n",
    "recall = (conf_mat[0][0]/(conf_mat[0][0] + conf_mat[0][1]) + conf_mat[1][1]/(conf_mat[1][1] + conf_mat[1][0]))/2\n",
    "print(\"Recall: \", recall)\n",
    "f1score = 2*(precision*recall)/(precision+recall)\n",
    "print(\"F1-Score: \", f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
